# Содержание

- **[Теория множеств](#Теория-множеств)**
- **[Пространства элементарных событий](#Пространства-элементарных-событий)**
- **[Аксиомы теории вероятности](#Аксиомы-теории-вероятности)**
- **[Условная вероятность](#Условная-вероятность)**
- **[Случайная величина. Закон ее распределения.](#Случайная-величина.-Закон-ее-распределения.)**
- **[Непрерывная с. в.](#Непрерывная-с.-в.)**
- **[Числовые характеристики с. в.](#Числовые-характеристики-с. в.)**

# Теория множеств

- Множеством называется любая совокупность объектов произвольной природы, каждый из которых называется элементом множества.
- Бесконечное множество называется счетным, если все его члены можно расположить в какой–то последовательности, перенумеровать.
- Два множества `А` и `Б` совпадают (или равны), если они состоят из одних и тех же элементов.
- Пустым множеством называется множество, не содержащее ни одного элемента.
- Множество `Б` называется подмножеством (частью) множества `А`, если все элементы `Б` содержатся также и `А`.
- Объединением (суммой) множеств `А` и `Б` называется множество `С = А + Б`, состоящее из всех элементов `А` и всех элементов `Б`.
- Пересечением (произведением) множеств `А` и `Б` называется множество `Д = А * Б`, состоящее из элементов одновременно входящих и в `А`, и в `Б`.

# Пространства элементарных событий

- Можно различать составные события и элементарные события. Где составное событие есть совокупность элементарных событий.
- Каждый неразложимый исход опыта представляется одним и только одним элементарным событием.
- Совокупность всех элементарных событий называется пространством элементарных событий, а все элементарные события — точками этого пространства.
- Пространство элементарных событий называется дискретным, если оно состоит лишь из конечного числа точек или из такого бесконечного числа точек, что они могут быть разложены в простую последовательность.
- Вероятность `P {A}` события `А` есть сумма вероятностей элементарных событий, составляющих событие `А`.

# Аксиомы теории вероятности

- Несколько событий `А1, А2, ..., Аn` образуют полную группу, если их сумма есть достоверное событие.
- Два события называют несовместными, если их соответствующие множества не пересекаются. 
- Несколько событий `А1, А2, ..., Аn` называются попарно несовместными (или просто несовместными), если появление любого из них исключает появление каждого из остальных (то есть их пересечение есть пустое множество).
- Суммой двух событий `А` и `Б` называется событие `С`, состоящее в выполнении события `А` или события `Б`, или обоих событий вместе.
- Суммой нескольких событий называется событие, состоящее в выполнении хотя бы одного из этих событий.
- Произведением двух событий `А` и `Б` называется событие `Д`, состоящее в совместномы выполнении события `А` и события `Б`.
- Противоположным по отношению к событию `А` называется событие `не А`, состоящее в непоявлении `А` и, значит, дополняющего его до пространства элементарных событий.
- Вероятность события есть функция множества.
- Вероятность любого события заключается между нулем и единицей.
- Если `А` и `Б` несовместые события, то `Р(А + Б) = Р(А) + Р(Б)`. Вероятность суммы несовместных событий равна сумме вероятностей этих событий.
- События образуют полную группу, если их сумма есть полное пространство элементарных событий. 
- События равновозможны, если их вероятности равны.
- Если события группы образуют полную группу, несовместны и равновозможны, то их называют случаями.
- Сумма вероятностей противоположных событий равна единице: `Р(А) + Р(не А) = 1`.
- Если события `А` и `Б` совместны, то `Р(А + Б) = Р(А) + Р(Б) - Р(АБ)`.

# Условная вероятность

- Условной вероятностью события `Б` при наличии `А` называется величина `Р(А|Б) = Р(АБ)/Р(А)`.
- Вероятность произведения (пересечения) двух событий равна вероятности одного из них, умноженной на условную вероятность второго при наличии первого: `Р(АБ) = Р(А) * Р(Б|А)`. Это правило умножения вероятностей.
- Вероятность произведения нескольких событий равна произведению вероятностей этих событий, причем вероятность каждого последующего события вычисляется при условии, что все предыдущие имели место.
- События `А` называется независимым от события `Б`, если его вероятность не зависит от того, произошло `Б` или нет. То есть: `Р(А|Б) = Р(А)`.
- Два события называются независимыми, если появление одного из них не меняет вероятности появления другого.
- Вероятность произведения двух независимых событий равна произведению вероятностей этих событий: `Р(АБ) = Р(А) * Р(Б)`.
- Попарная независимость событий еще не означает их независимость в совокупности.
- Если в задаче противоположное событие `не А` распадается на меньшее число вариантов, чем интересующее нас `А`, то имеет смысл при вычислении вероятности переходить к противоположному событию.
- Полная вероятность `Р(А) = SUMi [ Р(Нi) * Р(А|Hi) ]`.
- Формула Бейеса: `Р(Hi|А) = [Р(Hi) * Р (А|Hi)] / SUMi [ Р(Нi) * Р(А|Hi) ]`.

# Случайная величина. Закон ее распределения.

- Случайная величина `Х` есть функция элементарного события: `X = fi(w)`, где `w` — элементарное событие, принадлежащее пространству элементарных событий. Множество возможных значений с. в. `Х` состоит из всех значений, которые принимает функция `fi(w)`.
- Если множество возможных значений конечно или счетно, с. в. `Х` называется дискретной, если несчетно — недискретной.
- Закон распределения с. в. называется любое правило (таблица, функция), позволяющее находить вероятности всевозможных событий, связанных со случайной величиной.
- Функцией распределения с. в. `Х` называется вероятность того, то она примет значение меньшее, чем заданное `х`: `F(x) = P {X < x}`. Геометрически функция распределения интерпретируется как вероятность того, что случайная точка `Х` попадает левее заданной точки `х`.
- Основные свойства функции распределения:

  - `F(x)` — неубывающая функция своего аргумента, те при `x1 < x2`, `F(x1) <= F(x2)`.
  - `F(-inf) = 0`.
  - `F(+inf) = 1`.

- Вероятность того, что с. в. `Х` в результате опыта попадет на участок от `alpha` до `beta` равна приращению функции распределения на этом участке: `Р {alpha <= X <= beta} = F(beta) – F(alpha)`.
- Вероятность события `{X = alpha}` равна величине скачка ф. р. с. в. `Х` в точке `alpha`.
- Функция распределения любой дискретной случайной величины есть разрывная ступенчатая функция, скачки которой происходят в точках, соответствующих возможным значениям с. в и равны вероятностям этих значений.
- Индикатором события `А` называется с. в. `U`, равная единице, если в результате опыта событие `А` произошло, и нулю — если не произошло.


# Непрерывная с. в.

- С. в. `Х` является непрерывной, если ее функция распределения не только непрерывна в любой точке, но и дифференцируема всюду, кроме может быть отдельных точек, где она терпит излом. 
- Так как для непрерывных с. в. функция `F(x)` нигде не имеет скачков, то вероятность любого отдельного значения непрерывной случайной величины равна нулю: `P {X = alpha} = 0`.
- Вероятность попадания с. в. `Х` на любой участок `dx` будет интерпретироваться как масса, приходящаяся на этот участок, а средняя плотность на этом участке — как отношение массы к длине; на участке `[х, x + dx)` средняя площадь будет равна: `P {x <= X < x + dx} / dx`. То есть вероятность попадания с. в. `Х` на участок `[x, x+ dx)` равна приращению функции распределения на этом участке.
- Плотность распределения (вероятности) непрерывной с. в. `Х` в точке х называется производная ее функции распределения в этой точке: `f(x) = F'(x) = dF(x)/dx`.
- График плотности распределения `f(x)` называется кривой распределения.
- Вероятность попадания с. в. `Х` на участок `dx` равна `f(x)dx`. `f(x)dx` — называется элементом вероятности для точки `х`.
- Вероятность попадания с. в. `Х` на участок `(a, b)` равна сумме элементов вероятности на всем этом участке: `P {a < X < b} = int(a, b) [f(x) dx]`.
- Функция распределения `F(x) = P {X < x} = P {-inf < X < x} = int(-inf, x) [f(x)dx]`.
- Основные свойства плотности распределения:

  - `f(x) >= 0`.
  - `int(-inf, +inf)[f(x)dx] = 1`.

- Функция распределения не имеет размерности. Плотность распределения обратная размерности с. в. `Х`.
- Интегральная формула полной вероятности: `Р(А) = int(-inf, +inf)[P(A|x) * f(x) dx]`.
- Интегральная формула Бейеса: `fa(x) = f(x) * P(A|x) / P(A)`.

# Числовые характеристики с. в.

- Математическое ожидание (среднее значение) дискретной с. в. называется сумма произведений всех возможных ее значений на вероятности этих значений: `M[X] = SUMi xi*pi`.
- Математическое ожидание (среднее значение) н. с. в. `М[X] = int(-inf, +inf)[x*f(x)dx]`.
- Модой с. в. называется ее наиболее вероятное значение.
- Если вероятность или плотность вероятности достигают максимума не в одной, а в нескольких точках, распределение называется полимодальным. 
- Наличие более чем одной моды часто указывает на разнородность статистического материала, легшего в основу исследования.
- Медиана н. с. в. `Х` называется такое ее значение `xm`, для которого `P {X < xm} = P {X > xm} = ½`, то есть одинаково вероятно, окажется ли с. в. `Х` меньше `mx` или больше `mx`. Геометрически медиана — это абсцисса той точки, на оси Ох, для которой площади лежащие слева и справа от нее одинаковы и равны ½.
- Начальным моментом s-го порядка с. в. `Х` называется математическое ожидание s-й степени этой величины: `alpha_s[X] = M[X^s] = SUMi xi^s * pi`.
- Математическое ожидание есть первый начальный момент.
- Центрированной с. в. называется отклонение с. в. от ее математического ожидания: `X" = X - mx`.
- Центрирование с. в. равносильно переносу начала отсчета в точку `mx`.
- Моменты центрированной с. в. называются центральными моментами. 
- Центрированным моментом порядка `s` c. в. `Х` называется м. о. s-й степени центрированной с. в.: `mu_s[X] = M[X”^s] = M[(X - mx)^s] = SUMi (xi - mx)^s * pi`.
- Второй центральный момент называется дисперсией с. в.
- Дисперсия есть `Dx = M[X^2] - (M[X])^2 = M[(X-mx)^2]`.
- Дисперсия с. в. есть характеристика рассеивания разбросанности с. в. около ее математического ожидания.
- Среднеквадратическое отклонение `sigma[X] = sqrt(Dx)`.
- Для неотрицательной с. в. `Х` в качестве характеристики «степени ее случайности» иногда применяется коэффициент вариации: `v = sigma/mx`.
- Третий центральный момент служит характеристики асимметрии (скошенности) распределения.
- Если распределение симметрично относительно м. о. то все центральные моменты нечетного порядка равны нулю.
- Четвертый центральный момент служит для характеристики крутости распределения.
- Некоторые свойства с. в.

  - `M[c] = c`.
  - `D[c] = 0`.
  - `M[X + c] = M[X] + c`.
  - `D[X + c] = D[X]`.
  - `M[c*X] = c* M[X]`.
  - `D[c*X] = c^2 * D[X]`.

- Производящей функцией для с. в. для с. в. `X` называется функция вида: `fi(z) = SUMk pk*z^k`, где `z` — произвольный параметр `(0 < z <= 1)`.
- Математическое ожидание неотрицательной целочисленной с. в. равно первой производной ее производящей функции при `z = 1`.
- Второй начальный момент с. в. равен сумме второй производной от производящей функции при `z = 1` плюс ее мат. ожидание.
- Ковариацией случайных величин `X` и `Y` называются `cov(X, Y) = E[(X - mx) * (Y - my)] = E[X*Y] - mx*my`.
- Если `X` и `Y` независимы, то `cov(X, Y) = 0`. Обратное не верно.
- Если `X1, ..., Xn` — случайные величины с конечными дисперсиями `sigma^2_1, …, sigma^2_n` и `Sn = X1 + ... + Xn`, то `D(Sn) = SUM sigma^2 + 2 * SUM cov(Xi, Xj)`.
- Коэффициент корреляции: `ro(X, Y) = cov(X, Y)/ (sigma_x * sigma_y)`.
